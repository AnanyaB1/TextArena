<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>textarena.agents.basic_agents &#8212; TextArena 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=27fed22d" />
    <script src="../../../_static/documentation_options.js?v=8d563738"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for textarena.agents.basic_agents</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">import</span> <span class="nn">openai</span><span class="o">,</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span> 

<span class="kn">from</span> <span class="nn">textarena.core</span> <span class="kn">import</span> <span class="n">Agent</span>
<span class="kn">import</span> <span class="nn">textarena</span> <span class="k">as</span> <span class="nn">ta</span> 

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;HumanAgent&quot;</span><span class="p">,</span>
    <span class="s2">&quot;OpenRouterAgent&quot;</span><span class="p">,</span>
    <span class="s2">&quot;HFLocalAgent&quot;</span><span class="p">,</span>
    <span class="s2">&quot;CerebrasAgent&quot;</span>
<span class="p">]</span>


<span class="n">STANDARD_GAME_PROMPT</span> <span class="o">=</span> <span class="s2">&quot;You are a competitive game player. Make sure you read the game instructions carefully, and always follow the required format. The first action returned in squared brackets will be used.&quot;</span>
    
<div class="viewcode-block" id="HumanAgent">
<a class="viewcode-back" href="../../../source/textarena.agents.html#textarena.agents.basic_agents.HumanAgent">[docs]</a>
<span class="k">class</span> <span class="nc">HumanAgent</span><span class="p">(</span><span class="n">Agent</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Human agent class that allows the user to input actions manually.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the human agent.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            model_name (str): The name of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">observation</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process the observation and return the action.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            observation (str): The input string to process.</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            str: The response generated by the agent.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Please enter the action: &quot;</span><span class="p">)</span></div>



<span class="c1"># class OpenRouterAgent(Agent):</span>
<span class="c1">#     &quot;&quot;&quot;</span>
<span class="c1">#     GPT agent class that uses the OpenRouter API to generate responses.</span>
<span class="c1">#     &quot;&quot;&quot;</span>
<span class="c1">#     def __init__(</span>
<span class="c1">#         self, </span>
<span class="c1">#         model_name: str,</span>
<span class="c1">#         system_prompt: Optional[str]=None,</span>
<span class="c1">#         verbose: Optional[bool]=False</span>
<span class="c1">#     ):</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         Initialize the GPT agent.</span>
        
<span class="c1">#         Args:</span>
<span class="c1">#             model_name (str): The name of the model.</span>
<span class="c1">#             system_prompt (str): The system prompt to use (default: &quot;You are a competitive game player.&quot;).</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         super().__init__()</span>
<span class="c1">#         self.model_name = model_name</span>
<span class="c1">#         self.verbose = verbose</span>

<span class="c1">#         ## Set the OpenAI API key</span>
<span class="c1">#         openai.api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)</span>
<span class="c1">#         if not openai.api_key:</span>
<span class="c1">#             raise ValueError(&quot;OPENAI API key not found. Please set the OPENAI_API_KEY environment variable.&quot;)</span>
        
<span class="c1">#         ## Initialize the OpenAI client</span>
<span class="c1">#         self.client = openai.OpenAI(base_url=&quot;https://openrouter.ai/api/v1&quot;)</span>

<span class="c1">#         ## Set the system prompt</span>
<span class="c1">#         if system_prompt is None:</span>
<span class="c1">#             self.system_prompt = &quot;You are a competitive game player. Make sure you read the game instructions carefully, and always follow the required format.&quot;</span>
<span class="c1">#         else:</span>
<span class="c1">#             self.system_prompt = system_prompt</span>

    
<span class="c1">#     def __call__(</span>
<span class="c1">#         self, </span>
<span class="c1">#         observation: str</span>
<span class="c1">#     ) -&gt; str:</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         Process the observation using the OpenAI model and return the action.</span>
        
<span class="c1">#         Args:</span>
<span class="c1">#             observation (str): The input string to process.</span>
        
<span class="c1">#         Returns:</span>
<span class="c1">#             str: The response generated by the model.</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         assert isinstance(observation, str), \</span>
<span class="c1">#             f&quot;When uisng OpenRouter, the observation must be a string. Received type: {type(observation)}&quot;</span>
<span class="c1">#         try:</span>
<span class="c1">#             response = self.client.chat.completions.create(</span>
<span class="c1">#                 model=self.model_name,</span>
<span class="c1">#                 messages=[</span>
<span class="c1">#                     {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: self.system_prompt},</span>
<span class="c1">#                     {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: observation}</span>
<span class="c1">#                 ],</span>
<span class="c1">#                 # max_tokens=150, ## optional</span>
<span class="c1">#                 n=1,</span>
<span class="c1">#                 stop=None,</span>
<span class="c1">#                 temperature=0.7,</span>
<span class="c1">#             )</span>
<span class="c1">#             if self.verbose:</span>
<span class="c1">#                 print(f&quot;\nObservation: {observation}\n Response: {response}&quot;)</span>
<span class="c1">#             # Extract the assistant&#39;s reply</span>
<span class="c1">#             action = response.choices[0].message.content.strip()</span>
<span class="c1">#             return action</span>
<span class="c1">#         except Exception as e:</span>
<span class="c1">#             time.sleep(10_000)</span>
<span class="c1">#             # raise E</span>
<span class="c1">#             return f&quot;An error occurred: {e}&quot;</span>



<div class="viewcode-block" id="OpenRouterAgent">
<a class="viewcode-back" href="../../../source/textarena.agents.html#textarena.agents.basic_agents.OpenRouterAgent">[docs]</a>
<span class="k">class</span> <span class="nc">OpenRouterAgent</span><span class="p">(</span><span class="n">Agent</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    GPT agent class that uses the OpenRouter API to generate responses.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">system_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the GPT agent.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            model_name (str): The name of the model.</span>
<span class="sd">            system_prompt (str): The system prompt to use (default: &quot;You are a competitive game player.&quot;).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="c1">## Set the OpenAI API key</span>
        <span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">openai</span><span class="o">.</span><span class="n">api_key</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;OPENAI API key not found. Please set the OPENAI_API_KEY environment variable.&quot;</span><span class="p">)</span>
        
        <span class="c1">## Initialize the OpenAI client</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">(</span><span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;https://openrouter.ai/api/v1&quot;</span><span class="p">)</span>

        <span class="c1">## Set the system prompt</span>
        <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">STANDARD_GAME_PROMPT</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">system_prompt</span>

    
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">observation</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process the observation using the OpenAI model and return the action.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            observation (str): The input string to process.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            str: The response generated by the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> \
            <span class="sa">f</span><span class="s2">&quot;When uisng OpenRouter, the observation must be a string. Received type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
                    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">},</span>
                        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">observation</span><span class="p">}</span>
                    <span class="p">],</span>
                    <span class="c1"># max_tokens=150, ## optional</span>
                    <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">stop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="c1"># temperature=0.7,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Observation: </span><span class="si">{</span><span class="n">observation</span><span class="si">}</span><span class="se">\n</span><span class="s2"> Response: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="c1"># Extract the assistant&#39;s reply</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                <span class="k">return</span> <span class="n">action</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">pass</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="c1"># exit()</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model failed. going to sleep&quot;</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">10_000</span><span class="p">)</span></div>

        <span class="c1"># try:</span>
        <span class="c1">#     response = self.client.chat.completions.create(</span>
        <span class="c1">#         model=self.model_name,</span>
        <span class="c1">#         messages=[</span>
        <span class="c1">#             {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: self.system_prompt},</span>
        <span class="c1">#             {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: observation}</span>
        <span class="c1">#         ],</span>
        <span class="c1">#         # max_tokens=150, ## optional</span>
        <span class="c1">#         n=1,</span>
        <span class="c1">#         stop=None,</span>
        <span class="c1">#         temperature=0.7,</span>
        <span class="c1">#     )</span>
        <span class="c1">#     if self.verbose:</span>
        <span class="c1">#         print(f&quot;\nObservation: {observation}\n Response: {response}&quot;)</span>
        <span class="c1">#     # Extract the assistant&#39;s reply</span>
        <span class="c1">#     action = response.choices[0].message.content.strip()</span>
        <span class="c1">#     return action</span>
        <span class="c1"># except Exception as e:</span>
        <span class="c1">#     print(f&quot;\n\n{e}&quot;)</span>
        <span class="c1">#     time.sleep(10_000)</span>
        <span class="c1">#     # raise E</span>
        <span class="c1">#     return f&quot;An error occurred: {e}&quot;</span>
            


<div class="viewcode-block" id="HFLocalAgent">
<a class="viewcode-back" href="../../../source/textarena.agents.html#textarena.agents.basic_agents.HFLocalAgent">[docs]</a>
<span class="k">class</span> <span class="nc">HFLocalAgent</span><span class="p">(</span><span class="n">Agent</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Hugging Face local agent class that uses the Hugging Face Transformers library.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">quantize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the Hugging Face local agent.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            model_name (str): The name of the model.</span>
<span class="sd">            quantize (bool): Whether to load the model in 8-bit quantized format (default: False).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1">## Initialize the Hugging Face model and tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="p">,</span> 
            <span class="p">)</span>
        
        <span class="k">if</span> <span class="n">quantize</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="p">,</span> 
                <span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">device_map</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_name</span><span class="p">,</span>
                <span class="n">device_map</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1">## Initialize the Hugging Face pipeline</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
            <span class="s1">&#39;text-generation&#39;</span><span class="p">,</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> 
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> 
            <span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">observation</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process the observation using the Hugging Face model and return the action.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            observation (str): The input string to process.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            str: The response generated by the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate a response</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span>
                <span class="n">STANDARD_GAME_PROMPT</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">+</span><span class="n">observation</span><span class="p">,</span> 
                <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                <span class="n">return_full_text</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Extract and return the text output</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;generated_text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">action</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span></div>




<div class="viewcode-block" id="CerebrasAgent">
<a class="viewcode-back" href="../../../source/textarena.agents.html#textarena.agents.basic_agents.CerebrasAgent">[docs]</a>
<span class="k">class</span> <span class="nc">CerebrasAgent</span><span class="p">(</span><span class="n">Agent</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Cerebras agent class that uses the Cerebras API to generate responses.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the Cerebras agent.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_name (str): The name of the model.</span>
<span class="sd">            system_prompt (str): The system prompt to use (default: &quot;You are a competitive game player.&quot;).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        
        <span class="kn">from</span> <span class="nn">cerebras.cloud.sdk</span> <span class="kn">import</span> <span class="n">Cerebras</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">Cerebras</span><span class="p">(</span>
            <span class="c1"># This is the default and can be omitted</span>
            <span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;CEREBRAS_API_KEY&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1">## Set the system prompt</span>
        <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&quot;You are a competitive game player. Make sure you read the game instructions carefully, and always follow the required format.&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">system_prompt</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process the observation using the Cerebras model and return the action.</span>

<span class="sd">        Args:</span>
<span class="sd">            observation (str): The input string to process.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: The response generated by the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
                <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">observation</span><span class="p">},</span>
                <span class="p">],</span>
                <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Extract the assistant&#39;s reply</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">action</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">TextArena</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../source/modules.html">textarena</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Leon Guertler, Bobby Cheng.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>